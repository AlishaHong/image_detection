{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b92a1b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e27dd71-2b43-48bf-9f05-eba66c1afe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model with 2 GPUs\n",
    "results = model.train(data='data.yaml', epochs=100, imgsz=640, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5bf496c-65c0-4bc8-b076-e626ad5d87cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.12  Python-3.10.14 torch-2.4.1 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "'8th_11times_34/data.yaml' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_pt/11_전체ETC제거_3_4_데이터유지_8_6_total_remove_etc_with_34_11time_others_5times/best.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# load a custom model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Validate the model\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# no arguments needed, dataset and settings remembered\u001b[39;00m\n\u001b[0;32m     10\u001b[0m metrics\u001b[38;5;241m.\u001b[39mbox\u001b[38;5;241m.\u001b[39mmap    \u001b[38;5;66;03m# map50-95\u001b[39;00m\n\u001b[0;32m     11\u001b[0m metrics\u001b[38;5;241m.\u001b[39mbox\u001b[38;5;241m.\u001b[39mmap50  \u001b[38;5;66;03m# map50\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SBA\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ultralytics\\engine\\model.py:635\u001b[0m, in \u001b[0;36mModel.val\u001b[1;34m(self, validator, **kwargs)\u001b[0m\n\u001b[0;32m    632\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[0;32m    634\u001b[0m validator \u001b[38;5;241m=\u001b[39m (validator \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidator\u001b[39m\u001b[38;5;124m\"\u001b[39m))(args\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[1;32m--> 635\u001b[0m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m validator\u001b[38;5;241m.\u001b[39mmetrics\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m validator\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[1;32mc:\\Users\\SBA\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\SBA\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ultralytics\\engine\\validator.py:144\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[1;34m(self, trainer, model)\u001b[0m\n\u001b[0;32m    141\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting batch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input of shape (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 3, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassify\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m check_cls_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msplit)\n",
      "File \u001b[1;32mc:\\Users\\SBA\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ultralytics\\data\\utils.py:269\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[1;34m(dataset, autodownload)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_det_dataset\u001b[39m(dataset, autodownload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m    Download, verify, and/or unzip a dataset if not found locally.\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124;03m        (dict): Parsed dataset information and paths.\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# Download (optional)\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     extract_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\SBA\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ultralytics\\utils\\checks.py:521\u001b[0m, in \u001b[0;36mcheck_file\u001b[1;34m(file, suffix, download, download_dir, hard)\u001b[0m\n\u001b[0;32m    519\u001b[0m files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;28mstr\u001b[39m(ROOT \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m file), recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;28mstr\u001b[39m(ROOT\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m/\u001b[39m file))  \u001b[38;5;66;03m# find file\u001b[39;00m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[1;32m--> 521\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiple files match \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, specify exact path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiles\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: '8th_11times_34/data.yaml' does not exist"
     ]
    }
   ],
   "source": [
    "# Validate model\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('best_pt/11_전체ETC제거_3_4_데이터유지_8_6_total_remove_etc_with_34_11time_others_5times/best.pt')  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map    # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps   # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5576d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# # 모델 불러오기\n",
    "# model = YOLO('runs/detect/1st_open_reo_8_n_T4/weights/best.pt')\n",
    "\n",
    "# # 예측 수행\n",
    "# results = model('test_eclipse.jpg', save=True, imgsz=640, conf=0.2)\n",
    "\n",
    "# # 결과 출력 (선택적)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d5565fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28af2e54-9d78-4da5-8fa7-137344fcfd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\SBA\\repository\\image_detection\\test_eclipse.jpg: 480x640 1 eclipse, 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 86.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'snack', 1: 'hush', 2: 'eclipse'}\n",
       " obb: None\n",
       " orig_img: array([[[ 92, 122, 169],\n",
       "         [ 87, 117, 164],\n",
       "         [ 98, 131, 177],\n",
       "         ...,\n",
       "         [ 93, 119, 155],\n",
       "         [ 98, 122, 158],\n",
       "         [107, 131, 167]],\n",
       " \n",
       "        [[ 90, 120, 167],\n",
       "         [ 84, 114, 161],\n",
       "         [ 89, 122, 168],\n",
       "         ...,\n",
       "         [ 98, 124, 160],\n",
       "         [101, 125, 161],\n",
       "         [105, 129, 165]],\n",
       " \n",
       "        [[ 84, 117, 163],\n",
       "         [ 83, 116, 162],\n",
       "         [ 84, 117, 163],\n",
       "         ...,\n",
       "         [102, 128, 164],\n",
       "         [103, 127, 163],\n",
       "         [102, 126, 162]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[165, 178, 170],\n",
       "         [166, 179, 171],\n",
       "         [166, 179, 171],\n",
       "         ...,\n",
       "         [116, 118,  96],\n",
       "         [118, 120,  98],\n",
       "         [119, 121,  99]],\n",
       " \n",
       "        [[164, 177, 169],\n",
       "         [165, 178, 170],\n",
       "         [165, 178, 170],\n",
       "         ...,\n",
       "         [122, 125, 100],\n",
       "         [121, 124,  99],\n",
       "         [119, 122,  97]],\n",
       " \n",
       "        [[166, 179, 171],\n",
       "         [164, 177, 169],\n",
       "         [163, 176, 168],\n",
       "         ...,\n",
       "         [136, 139, 114],\n",
       "         [141, 144, 119],\n",
       "         [146, 149, 124]]], dtype=uint8)\n",
       " orig_shape: (3024, 4032)\n",
       " path: 'c:\\\\Users\\\\SBA\\\\repository\\\\image_detection\\\\test_eclipse.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict3'\n",
       " speed: {'preprocess': 1.9981861114501953, 'inference': 21.99840545654297, 'postprocess': 86.36212348937988}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Prediction using trained model\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8n model\n",
    "model = YOLO('')\n",
    "\n",
    "# Run inference \n",
    "model.predict('test_eclipse.jpg', save=True, imgsz=640, conf=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa031e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !yolo detect predict model=yolov8n.pt source='test_eclipse.jpg' imgsz=640 conf=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f3d815e-d7ad-4f2d-b540-b3039f1230e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.12  Python-3.10.14 torch-2.4.1 CPU (12th Gen Intel Core(TM) i7-12700)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best_pt\\11_ETC_3_4__8_6_total_remove_etc_with_34_11time_others_5times\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (5.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.0...\n",
      "WARNING:tensorflow:From c:\\Users\\SBA\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.11M/1.11M [00:00<00:00, 1.94MB/s]\n",
      "Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to C:\\Users\\SBA\\repository\\image_detection\\calibration_image_sample_data_20x128x128x3_float32.npy...: 100%|██████████| 1/1 [00:00<00:00, 91.21file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.34...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.3s, saved as 'best_pt\\11_ETC_3_4__8_6_total_remove_etc_with_34_11time_others_5times\\best.onnx' (10.2 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.22.3...\n",
      "\u001b[31mERROR:\u001b[0m best_pt\\11_전체ETC제거_3_4_데이터유지_8_6_total_remove_etc_with_34_11time_others_5times\\best_saved_model is not a directory\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SBA\\anaconda3\\envs\\pytorch\\lib\\site-packages\\onnx2tf\\onnx2tf.py\", line 1216, in convert\n",
      "    tf.saved_model.save(concrete_func, output_folder_path)\n",
      "  File \"c:\\Users\\SBA\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\", line 1432, in save\n",
      "    save_and_return_nodes(obj, export_dir, signatures, options)\n",
      "  File \"c:\\Users\\SBA\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\", line 1474, in save_and_return_nodes\n",
      "    path_helpers.get_or_create_variables_dir(export_dir)\n",
      "  File \"c:\\Users\\SBA\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\saved_model\\path_helpers.py\", line 26, in get_or_create_variables_dir\n",
      "    file_io.recursive_create_dir(variables_dir)\n",
      "  File \"c:\\Users\\SBA\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 498, in recursive_create_dir\n",
      "    recursive_create_dir_v2(dirname)\n",
      "  File \"c:\\Users\\SBA\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 513, in recursive_create_dir_v2\n",
      "    _pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: best_pt\\11_전체ETC제거_3_4_데이터유지_8_6_total_remove_etc_with_34_11time_others_5times\\best_saved_model is not a directory\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success  25.7s, saved as 'best_pt\\11_ETC_3_4__8_6_total_remove_etc_with_34_11time_others_5times\\best_saved_model' (15.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.17.0...\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success  0.0s, saved as 'best_pt\\11_ETC_3_4__8_6_total_remove_etc_with_34_11time_others_5times\\best_saved_model\\best_float32.tflite' (10.2 MB)\n",
      "\n",
      "Export complete (26.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\SBA\\repository\\image_detection\\best_pt\\11_ETC_3_4__8_6_total_remove_etc_with_34_11time_others_5times\u001b[0m\n",
      "Predict:         yolo predict task=detect model=best_pt\\11_ETC_3_4__8_6_total_remove_etc_with_34_11time_others_5times\\best_saved_model\\best_float32.tflite imgsz=640  \n",
      "Validate:        yolo val task=detect model=best_pt\\11_ETC_3_4__8_6_total_remove_etc_with_34_11time_others_5times\\best_saved_model\\best_float32.tflite imgsz=640 data=8th_11times_34/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'best_pt\\\\11_전체ETC제거_3_4_데이터유지_8_6_total_remove_etc_with_34_11time_others_5times\\\\best_saved_model\\\\best_float32.tflite'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Export model to tflite\n",
    "\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('best_pt/11_전체ETC제거_3_4_데이터유지_8_6_total_remove_etc_with_34_11time_others_5times/best.pt')  # load a custom trained model\n",
    "\n",
    "# Export the model\n",
    "model.export(format='tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3aae33b-b14a-43f6-861f-3e0f2d21407f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading runs\\detect\\1st_open_reo_8_n_T4\\weights\\best_saved_model\\best_float32.tflite for TensorFlow Lite inference...\n",
      "\n",
      "image 1/1 c:\\Users\\SBA\\repository\\image_detection\\test_eclipse.jpg: 640x640 1 eclipse, 80.5ms\n",
      "Speed: 5.0ms preprocess, 80.5ms inference, 10.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'snack', 1: 'hush', 2: 'eclipse'}\n",
       " obb: None\n",
       " orig_img: array([[[ 92, 122, 169],\n",
       "         [ 87, 117, 164],\n",
       "         [ 98, 131, 177],\n",
       "         ...,\n",
       "         [ 93, 119, 155],\n",
       "         [ 98, 122, 158],\n",
       "         [107, 131, 167]],\n",
       " \n",
       "        [[ 90, 120, 167],\n",
       "         [ 84, 114, 161],\n",
       "         [ 89, 122, 168],\n",
       "         ...,\n",
       "         [ 98, 124, 160],\n",
       "         [101, 125, 161],\n",
       "         [105, 129, 165]],\n",
       " \n",
       "        [[ 84, 117, 163],\n",
       "         [ 83, 116, 162],\n",
       "         [ 84, 117, 163],\n",
       "         ...,\n",
       "         [102, 128, 164],\n",
       "         [103, 127, 163],\n",
       "         [102, 126, 162]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[165, 178, 170],\n",
       "         [166, 179, 171],\n",
       "         [166, 179, 171],\n",
       "         ...,\n",
       "         [116, 118,  96],\n",
       "         [118, 120,  98],\n",
       "         [119, 121,  99]],\n",
       " \n",
       "        [[164, 177, 169],\n",
       "         [165, 178, 170],\n",
       "         [165, 178, 170],\n",
       "         ...,\n",
       "         [122, 125, 100],\n",
       "         [121, 124,  99],\n",
       "         [119, 122,  97]],\n",
       " \n",
       "        [[166, 179, 171],\n",
       "         [164, 177, 169],\n",
       "         [163, 176, 168],\n",
       "         ...,\n",
       "         [136, 139, 114],\n",
       "         [141, 144, 119],\n",
       "         [146, 149, 124]]], dtype=uint8)\n",
       " orig_shape: (3024, 4032)\n",
       " path: 'c:\\\\Users\\\\SBA\\\\repository\\\\image_detection\\\\test_eclipse.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 5.00035285949707, 'inference': 80.51562309265137, 'postprocess': 10.000228881835938}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction using custom tflite model\n",
    "\n",
    "#  Prediction using trained model\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8n model\n",
    "model = YOLO('runs/detect/1st_open_reo_8_n_T4/weights/best_saved_model/best_float32.tflite')\n",
    "\n",
    "# Run inference \n",
    "model.predict('test_eclipse.jpg', save=True, imgsz=640, conf=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340d01d-6c54-4989-9f04-91206888e37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
